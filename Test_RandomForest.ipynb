{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, f1_score\n",
    "\n",
    "# Charger les données (supposons que les données sont dans un fichier CSV)\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\corre\\\\Desktop\\\\Wild Code School\\\\Projet 3\\\\GitHub\\\\semiology_AI-1\\\\diabete_folder\\\\Entrainement\\\\diabetes_base_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Utilisation et test d'une des methodes de prédiction : Random Forest Classifier\n",
    "\n",
    "Definition : Une forêt aléatoire est une méthode d'ensemble qui construit une multitude \n",
    "d'arbres de décision pendant l'entraînement et produit la classe mode (pour la classification)\n",
    "ou la moyenne des prédictions (pour la régression) de tous les arbres individuels. Elle utilise\n",
    "deux techniques principales pour introduire de la diversité dans les arbres : le bagging \n",
    "(bootstrap aggregating) et la sélection aléatoire de caractéristiques.\n",
    "\n",
    "Le but sera d'en tester plusieurs et ainsi de definir la plus performante.\n",
    "On normalisera les données dans cet entrainement et utiliseront egalement GridSearchCV pour \n",
    "determiner le meilleurs nombre d'arbres.\n",
    "\n",
    "Modele test avec toutes les variables\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Accuracy: 0.7337662337662337\n",
      "Recall Score: 0.6363636363636364\n",
      "F1 Score: 0.6306306306306306\n",
      "Best n_estimators: 600\n"
     ]
    }
   ],
   "source": [
    "# Séparation des caractéristiques et de la cible\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Définition du pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),                 # Normalisation des caractéristiques\n",
    "    ('classifier', RandomForestClassifier(random_state=42))  # Modèle de forêt aléatoire\n",
    "])\n",
    "\n",
    "# Création d'une grille de paramètres pour `n_estimators`\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300, 400, 500, 600, 700, 800, 1000]\n",
    "}\n",
    "\n",
    "# Recherche de grille avec validation croisée\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres et évaluation du modèle optimisé\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Évaluation du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Optimized Accuracy: {accuracy}\")\n",
    "print(\"Recall Score:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(f\"Best n_estimators: {grid_search.best_params_['classifier__n_estimators']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[98 25]\n",
      " [25 44]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       123\n",
      "           1       0.64      0.64      0.64        69\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.72      0.72      0.72       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le patient est probablement non-diabétique.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\corre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions sur un exemple de nouvelles données\n",
    "new_data = np.array([[2, 120, 70, 20, 80, 25.0, 0.5, 33]])\n",
    "prediction = best_model.predict(new_data)\n",
    "\n",
    "if prediction[0] == 1:\n",
    "    print(\"Le patient est probablement diabétique.\")\n",
    "else:\n",
    "    print(\"Le patient est probablement non-diabétique.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
